# Elasticsearch
- 검색이랑 데이터분석에 최적화된 데이터베이스

<br>

## ✅ 주요 활용 사례
1. 검색 최적화
    - 데이터가 많더라도 뛰어난 검색 속도를 가지고 있고, 오타나 동의어를 고려해서 유연하게 검색할 수 있는 기능을 가지고 있다
    - 쿠팡이나 배달의 민족의 검색 기능도 Elasticsearch 활용
2. 데이터 수집 및 분석
    - 대규모 데이터를 수집 및 분석하는데 최적화되어 있다


<br>

## 📝 간단 용어 대응표: RDB vs Elasticsearch

| RDB (관계형 DB)               | Elasticsearch                   |
| ----------------------------- | ------------------------------- |
| **Database**                  | **Index**                       |
| **Table**                     | **Type** (← 현재는 거의 폐지됨) |
| **Row**                       | **Document**                    |
| **Column**                    | **Field**                       |
| **Schema**                    | **Mapping**                   |
| **DBMS 서버 전체**            | **Cluster**                     |
| **DB 서버의 물리적 인스턴스** | **Node**                        |

<br>

### Elasticsearch 용어
- **인덱스** : 관련 문서를 저장하고 구조화하는 장소
    - **샤드** : 색인 및 검색 요청을 처리할 수 있는 루씬 인덱스의 인스턴스다
    - 인덱스는 프라이머리 샤드, 레플리카 샤드로 구성된다
    - **프라이머리 샤드**
        - 읽기 및 쓰기 요청을 모두 처리
    - **레플리카 샤드**
        - 읽기 전용
    - 프라이머리 및 레플리카 샤드는 항상 서로 다른 노드에 할당되어 다중성과 확장성을 제공
    - | 손실 상황                               | 시스템 동작                                                  | 영향                                | 자동 복구 여부 |
        | --------------------------------------- | ------------------------------------------------------------ | ----------------------------------- | -------------- |
        | **Primary Shard 손실 (Replica 존재)** | 클러스터가 **Replica를 새로운 Primary로 승격**               | ✅ 서비스 유지 가능 (읽기/쓰기 가능) | ✅ 자동 복구    |
        | **Replica Shard 손실 (Primary 존재)** | Primary는 정상이므로 영향 없음 Replica를 다시 다른 노드에 **자동 생성** | ✅ 서비스 지속 가능 (읽기/쓰기 가능) | ✅ 자동 복구    |
        | **Primary + Replica 모두 손실**       | 해당 샤드의 데이터 완전 소실 검색/색인 불가                  | ❌ 데이터 손실 서비스 장애 발생      | ❌ 불가능       |
- **색인(Indexing)** : 문서를 엘라스틱서치 인덱스에 기록하는 작업
- **document(문서)** : 인덱스에 저장된 JSON 객체
- **매핑** : 인덱스 내 필드들의 구조/데이터형을 정의, 각 필드의 데이터 유형을 지정하고 검색을 위해 필드를 색인하고 분석하는 방법을 결정
- **노드** : 엘라스틱서치의 단일 실행 인스턴스(하나의 실행 단위)

<br>

## 내부 구조
```scss
클러스터
 ├─ 노드 A
 │   ├─ 샤드: products 인덱스의 Primary-0
 │   └─ 샤드: logs 인덱스의 Replica-2
 ├─ 노드 B
 │   └─ 샤드: products 인덱스의 Replica-0
 │
└─ 인덱스
    ├─ products (2 primary shards, 1 replica each)
    │    ├─ Primary-0 → Node A
    │    ├─ Primary-1 → Node B
    │    ├─ Replica-0 → Node B
    │    └─ Replica-1 → Node A
    └─ logs ...
```
- 인덱스는 여러 개의 샤드로 나뉘고,
- 이 샤드들이 클러스터 내 여러 노드에 분산 저장된다

<br>

## 🔍 데이터 색인과 검색

<br>

### 인덱싱과 검색 성능 최적화
- 기본적으로 하나의 인덱스를 생성할 때
    - Primary Shard (기본 샤드): 1개
    - Replica Shard (복제 샤드): 1개 (Primary Shard의 복제본)
- 인덱스는 여러 개의 샤드로 구성될 수 있다
- 샤드 개수가 늘어날수록 데이터의 **확장성, 성능, 안정성**에 직결된다
- 너무 작은 데이터에 샤드를 많이 만들면 오히려 느려지고 비효율적이다

<br>

참고
> 레플리카 카드는 각 프라이머리 샤드마다 할당된다.   
> 예로는 2개의 프라이머리 샤드, 1개의 레플리카 샤드면 총 4개의 샤드 할당된다(각 프라이머리 샤드마다 1개의 레플리카 샤드)   
> 2개 프라이머리, 2개의 레플리카 인덱스는 총 6개 샤드로 구성

<br>

따라서
- 검색 성능 최적화 하려면 샤드를 전체 노드에 균등하게 분산해야 한다
- 30GB ~ 50GB 사이의 데이터를 저장하는 것을 권장
    - 예로는
    - 고성능 검색 -> 작은 샤드가 빠른 검색과 집계에 이점
    - 로깅 작업 -> 클러스터에 많은 데이터를 저장할 수 있게 큰 샤드가 적합

<br>

### 주요 데이터 타입들 

| 타입                       | 설명                                     |
| -------------------------- | ---------------------------------------- |
| `text`                     | 전체 텍스트 검색용 (ex. 제품명, 설명 등) |
| `keyword`                  | 정렬/집계용 문자열 (ex. 카테고리, ID 등) |
| `integer`, `float`, `long` | 숫자형 데이터                            |
| `boolean`                  | true / false                             |
| `date`                     | IPv4, IPv6                              |
| `geo_point`                | 위도/경도 좌표                           |
| `object`                   | JSON 문서에 내부 객체                    |
| `array`                    | 배열, 하나의 배열은 단일 데이터만 보유     |
| `nested`                   | 중첩 타입, 객체 내부의 연관성 정보 유지    |
| `join`                     | 문서 간에 부모/자식 관계를 만듬           |

<br>

### 문서 ID 생성
- 자동으로 문서 ID 생성하는 것이 더 효율적이며 색인 성능도 향상된다
    - 범용 고유 식별자(UUID)를 사용하므로
- 반면, ID를 직접 설정하면 색인 작업을 하기 전에 동일한 _id 프라이머리 샤드에 이미 존재하는지 확인하는 작업을 진행

<br>

### 매핑
- 엘라스틱서치는 자동으로 동적 인덱스 매핑을 생성할 수 있다
- 인덱스 매핑은 제거하거나 변경할 수 없다
- 따라서 인덱스 스키마를 알고 있다면 인덱스 매핑을 정의하는게 좋다

<br>

### 엘라스틱서치 노드
| 노드 종류                                 | 역할                                                         | 설정 키                              |
| ----------------------------------------- | ------------------------------------------------------------ | ------------------------------------ |
| 🌐 **마스터 노드 (Master Node)**           | 클러스터 상태 관리, 노드 추가/제거, 인덱스 생성 등 **전체 제어 역할** | `node.roles: [ master ]`             |
| 📦 **데이터 노드 (Data Node)**             | 실제 데이터를 저장하고, 색인(indexing), 검색(query) 처리 담당 | `node.roles: [ data ]`               |
| 🛠 **인제스트 노드 (Ingest Node)**         | 색인 전에 데이터를 전처리(파이프라인 실행 등)                | `node.roles: [ ingest ]`             |
| 💬 **코디네이팅 노드 (Coordinating Node)** | 사용자가 보낸 요청을 다른 노드에 전달하고 결과를 종합 → **프록시 역할** | 역할 없음 (`node.roles` 비워두면 됨) |
| 📁 **머신러닝 노드 (ML Node)**             | 머신러닝 분석 (anomaly detection 등) 담당                    | `node.roles: [ ml ]`                 |

<br>

### 예제 코드들
```shell
PUT /my-index
GET my-index
GET _cat/indices
PUT my-other-index
PUT my-other-index2
{
  "settings": {
    "index": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    }
  }
}
GET _cat/shards/my-other-index2?v
PUT my-index/_doc/2
{
  "city": "Japan"
}
GET my-index/_search
POST my-index/_doc/
{
  "city": 11.1
}
GET my-index/_mapping
PUT my-explicit-index
{
  "mappings": {
    "properties": {
      "year": {
        "type": "integer"
      },
      "city": {
        "type": "keyword"
      },
      "population_M": {
        "type": "float"
      },
      "attrations": {
        "type": "text"
      }
    }
  }
}
POST my-explicit-index/_doc
{
  "year": "aa",
  "city": "AA",
  "population_M":2.0,
  "attrations": "Queen"
}

GET my-explicit-index/_search

PUT stores
{
  "mappings": {
    "properties": {
      "suburb": {
        "type": "keyword"
      },
      "product": {
        "type": "nested"
      }
    }
  }
}

POST stores/_doc
{
  "suburb": "Carlton",
  "product": [
    {
      "product": "i20 Hatch",
      "quantity":21
    },
    {
      "product": "i30 Sport",
      "quantity":300
    }
  ]
}

GET stores/_search
{
  "query": {
    "nested": {
      "path": "product",
      "query": {
        "bool": {
          "must": [
            {"match": {"product.product.keyword": "i30 Sport"}}
          ]
        }
      }
    }
  }
}

PUT department-employees
{
  "mappings": {
    "properties": {
      "dept_id": { "type": "keyword"},
      "dept_name": {"type": "keyword"},
      "employee_id": {"type": "keyword"},
      "employee_name": {"type": "keyword"},
      "doc_type": {
        "type": "join",
        "relations": {
          "department": "employee"
        }
      }
    }
  }
}

PUT department-employees/_doc/d3
{
  "dept_id": "D003",
  "dept_name": "IT",
  "doc_type": "department"
}

PUT department-employees/_doc/e1?routing=1
{
  "employee_id": "E002",
  "employee_name": "James",
  "doc_type": {
    "name": "employee",
    "parent": "d3"
  }
}

PUT department-employees/_doc/e2?routing=1
{
  "employee_id": "E003",
  "employee_name": "Sara",
  "doc_type": {
    "name": "employee",
    "parent": "d3"
  }
}

GET department-employees/_search
{
  "query": {
    "has_parent": {
      "parent_type": "department",
      "query": {
        "term": {
          "dept_name": {
            "value": "IT"
          }
        }
      }
    }
  }
}
```

<br>

### 샘플 로그 색인
1. 3개 파일 생성
```sh
#!/bin/bash
printf "\n**Load.sh loads an index template and an ingest pipeline to process Apache web logs into Elasticsearch**\n\n"
echo -n "Elasticsearch cluster URL: "
read url
echo -n "Username: "
read username
echo -n "Password: "
read -s password
echo

# load index template
if curl -k -f -XPUT "$url/_index_template/web-logs" -u $username:$password -H 'Content-Type: application/json' -d "@web-logs-template.json"
then echo " - Loaded index template for web logs"
else echo " Could not load index template"
exit
fi

# load ingest pipeline
if curl -k -f -XPUT "$url/_ingest/pipeline/web-logs" -u $username:$password -H 'Content-Type: application/json' -d "@web-logs-pipeline.json"
then echo " - Loaded ingest pipeline for Apache"
else echo " Could not load ingest pipeline for Apache"
exit
fi

printf "\n*Loaded components successfully\n"
```
load.sh

<br>

```sh
https://github.com/wikibook/es80/tree/main/Chapter3
```
- 해당 주소에서 `web-logs-template.json`, `web-logs-pipeline.json` 다운

<br><br>

2. 같은 폴더에 위 3개의 파일을 생성시킨 후 `./load.sh` 실행
- url은 `https://localhost:9200`
    - `/etc/elasticsearch/elasticsearch.yml`에 아래 항목이 있다면 `https://`로 접속
    ```sh
    xpack.security.http.transport.enabled: true
    ``` 

<br>

아래와 같은 결과가 나오면 성공

<img src="../resources/log/elastic_load.png">

<br><br>

3. 로그스태시 다운
```sh
curl -O https://artifacts.elastic.co/downloads/logstash/logstash-8.14.0-linux-x86_64.tar.gz
```
다운로드가 완료되면 .tar 아카이브 파일의 압축을 푼다
```sh
tar -xzf logstash-8.14.0-linux-x86_64.tar.gz
```